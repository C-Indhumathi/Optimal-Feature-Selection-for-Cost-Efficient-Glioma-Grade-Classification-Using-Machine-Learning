ğŸ§  GLIOMA TUMOR GRADE CLASSIFICATION ğŸ“ Project Overview This project
focuses on developing aÂ robust and parsimoniousÂ (minimal) classification
model to accurately distinguish betweenÂ Lower Grade Glioma
(LGG)Â andÂ Glioblastoma (GBM).Â The classification utilizes a blend of
clinical features (Age, Gender, Race) and a panel of 20 common molecular
mutation markers. The primary goal is to identify theÂ optimal, minimal
feature subsetÂ required to achieve high predictive performance.

1.  Data Analysis and Key Clinical & Molecular Findings Initial
    Exploratory Data Analysis (EDA) revealed critical relationships for
    classifying tumor grade: 1.1. Key Clinical FindingsÂ  1.2. Key
    Molecular FindingsÂ 

2.  Feature Selection Methodology A rigorous, two-stage feature
    selection pipeline was implemented to refine the initial set of 23
    candidate features: Stage 1: Random Forest RankingÂ  Method:Â A Random
    Forest Classifier assigned an importance score to all features.
    Result:Â The ranking was dominated byÂ Age_at_diagnosisÂ (Â importance)
    andÂ IDH1 mutation statusÂ (Â importance). Output:Â The search space was
    reduced to theÂ Top 15Â ranked features. Stage 2: Optimal Subset
    Selection (Cross-Validation)Â  Method:Â Sequential testing using a
    Logistic Regression model with 5-Fold Cross-Validation (CV)
    maximized theÂ Macro F1-Score. Result:Â The highest F1-Score () was
    achieved withÂ Â features. Output:Â Features beyond this point were
    deemed redundant.

3.  The Optimal Feature Set and Model Foundation The final model is
    based on the followingÂ 8 features: Verification: Target
    Correlation:Â Confirmed thatÂ IDH1Â (LGG) andÂ Age_at_diagnosisÂ (GBM)
    provide the necessary strong, opposing signals to distinguish the
    grades. Multicollinearity:Â The subset isÂ stable and free of
    redundancyÂ due to low inter-feature correlation (maximumÂ ).

4.  Model Evaluation and Final Selection Three different classifiers
    were trained and evaluated on the optimal 8-feature subset using a
    hold-out test set (N=168). 4.1. Overall PerformanceÂ  4.2. Detailed
    Performance Metrics (Logistic Regression)Â  4.3. Final Selection
    Rationale TheÂ Logistic RegressionÂ model was selected as the final
    classifierÂ Â because: Highest Performance:Â It achieved the highest
    overallÂ Macro F1-Score (0.88)Â andÂ Accuracy (0.8750). Balanced
    Prediction:Â It demonstrated the best balance of class performance,
    achieving excellentÂ Recall for GBM (0.94)Â while maintaining
    strongÂ Precision for LGG (0.95). Interpretability (Primary
    Factor):Â Logistic Regression providesÂ direct, linear coefficients,
    which is essential in a clinical application.Â This allows clinicians
    to easily interpret the model's output.
